# -*- coding: utf-8 -*-
"""model 1 mnist dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_7pcmLzifW5KC3cZyjAvt4XuuY7EMKmB
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()

# DATA EXPLORATION AND PREPROCESSING

# Check the shape and data type
print("Original Training Data Shape:", X_train_full.shape) # Should be (60000, 28, 28)
print("Original Data Type:", X_train_full.dtype)     # Should be uint8

# Create a validation set and scale the data
# The first 5000 images are for validation, the rest for training.
X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0
y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
X_test = X_test / 255.0 # Also scale the test set

# Define class names for plotting
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
               "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

# Let's look at a sample image
plt.imshow(X_train[0], cmap="binary")
plt.axis('off')
plt.title(f"Class: {class_names[y_train[0]]}")
plt.show()

# NEURAL NETWORK ARCHITECTURE

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    # Input Layer: Flattens the 28x28 image into a 1D array of 784 pixels
    keras.layers.Flatten(input_shape=[28, 28]),

    # Hidden Layer 1: 300 neurons with ReLU activation
    keras.layers.Dense(300, activation="relu"),

    # Hidden Layer 2: 100 neurons with ReLU activation
    keras.layers.Dense(100, activation="relu"),

    # Output Layer: 10 neurons (one for each class) with Softmax activation
    keras.layers.Dense(10, activation="softmax")
])

# print a summary of the model
model.summary()

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])

# 6. TRAIN THE MODEL
# ------------------
# This will train the model and store the training history
history = model.fit(X_train, y_train, epochs=30,
                    validation_data=(X_valid, y_valid))

# Plotting the learning curves
import pandas as pd
pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)
plt.title("Model Training History")
plt.xlabel("Epochs")
plt.ylabel("Loss / Accuracy")
plt.show()

# Evaluate the model on the unseen test data
print("\nEvaluating on Test Data:")
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy:.4f}")

# MAKE PREDICTIONS
X_new = X_test[:4]
y_proba = model.predict(X_new)

y_pred = np.argmax(y_proba, axis=1)
print("\nPredictions for first 3 test images:", y_pred)
print("Actual labels for first 3 test images:", y_test[:4])

predicted_classes = np.array(class_names)[y_pred]
print("Predicted classes:", predicted_classes)

# Display the images with their predicted labels
plt.figure(figsize=(7, 3))
for index, image in enumerate(X_new):
    plt.subplot(1, 4, index + 1)
    plt.imshow(image, cmap="binary")
    plt.axis('off')
    plt.title(f"Predicted: {predicted_classes[index]}\nActual: {class_names[y_test[index]]}")
plt.tight_layout()
plt.show()

X_new = X_test[:25]
y_proba = model.predict(X_new)

y_pred = np.argmax(y_proba, axis=1)

n_rows = 5
n_cols = 5
plt.figure(figsize=(n_cols * 1.6, n_rows * 1.6))
for row in range(n_rows):
    for col in range(n_cols):
        index = n_cols * row + col
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(X_test[index], cmap="binary")
        plt.axis('off')
        plt.title(class_names[y_test[index]], fontsize=14)
plt.tight_layout()
plt.show()